settings:
  env:
    JAR: null
    DATA_FHIR_SERVER_DETAILS: null
    MEASURE_FHIR_SERVER_DETAILS: null
    TESTS_JSON: tests/src/main/resources/performance/performance-regression-tests.json

execution:
  - executor: pytest
    scenario: thousand-patients-five-measures
    env:
      TESTS_JSON: tests/src/main/resources/performance/one-thousand-patients-five-measures.json

# Each label for a scenario has to match the the string output by pytest parameterize for a test case.
# If it does not, then the criteria will be skipped by Taurus.
scenarios:
  thousand-patients-five-measures:
    script: /bzt-configs/tests/src/main/python/TestDriver_MeasurePerformance.py
    criteria:
      - subject: p99.9
        condition: '>'
        threshold: 4800s
        label: 'test[tests/src/main/resources/measure-parameters/performance/fivePerformanceMeasures.json-targets0-1000 Patients 5 Measures]'
        message: One thousand patients, 5 measures took longer than 4800 seconds

modules:
  local:
    sequential: true

reporting:
  - module: passfail
  - module: junit-xml
    filename: /bzt-configs/tests/results/performanceCTTests.xml
    data-source: pass-fail
